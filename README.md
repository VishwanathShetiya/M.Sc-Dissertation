# ğŸ§  M.Sc Dissertation â€“ BERT Inference Microarchitectural Exploration

This repository contains the dissertation work completed during my **Master of Science in Mathematics with a specialization in Computer Science**. The project focuses on the **microarchitectural characterization and optimization of transformer-based deep learning (DL) models**, specifically the **BERT Base Uncased** model, on an **Intel Skylake CPU** using **PyTorch**.

---

## ğŸ“ Repository Structure

.
â”œâ”€â”€ Presentations/
â”‚ â”œâ”€â”€ Transformers Architecture
â”‚ â”œâ”€â”€ BERT Base Uncased Model
â”‚ â””â”€â”€ Final Project Presentation
â”œâ”€â”€ Thesis/
â”‚ â””â”€â”€ Final Thesis Document (PDF/LaTeX)
â”œâ”€â”€ Papers that I Studied/
â”‚ â””â”€â”€ Reference Research Papers


---

## ğŸ§¾ Project Overview

This project investigates the **microarchitectural behavior of transformer-based DL models**â€”a key class of models in modern **machine learning (ML)**â€”by profiling the **BERT Base Uncased** inference workload on an **Intel Skylake CPU**. The goal is to understand how efficiently these models execute on general-purpose processors and identify performance bottlenecks at the hardware level.

---

## ğŸ” Key Objectives

- Explore computational patterns and resource usage of transformer DL models in ML workloads.
- Profile the inference performance of BERT Base Uncased on Intel Skylake using **PyTorch**.
- Apply **Intel VTune Profiler** with a **top-down microarchitectural analysis** methodology to identify CPU pipeline bottlenecks.
- Pinpoint hotspot functions and inefficient hardware resource utilization impacting DL inference performance.

---

## ğŸ› ï¸ Tools & Methodology

- **PyTorch** deep learning framework
- **Intel VTune Profiler** for microarchitectural performance profiling
- **Top-down analysis methodology** to analyze CPU resource usage
- Intel Core **Skylake** microarchitecture as the hardware platform

---

## ğŸ“ˆ Findings & Contribution

- Discovered critical microarchitectural bottlenecks limiting BERT inference performance on Skylake CPUs.
- Proposed a theoretical hardware enhancementâ€”adding an **execution port**â€”to improve throughput and efficiency.
- Provided insights into optimizing transformer DL workloads on CPU architectures widely used in latency-sensitive or resource-constrained ML applications.

---

## ğŸ§© Significance

This research deepens the understanding of DL and ML workloads on CPU architectures, offering valuable guidance for:

- Hardware-aware optimization of ML inference
- Performance tuning of transformer models in CPU environments
- Future CPU microarchitecture enhancements tailored for DL workloads
